# app.py
import streamlit as st
import document_processor as dp
import json
import traceback
import pandas as pd
import time

# --- Helper Functions ---
def count_short_nodes(node, threshold, count=0):
    """ì¬ê·€ì ìœ¼ë¡œ íŠ¸ë¦¬ë¥¼ ìˆœíšŒí•˜ë©° í…ìŠ¤íŠ¸ê°€ ì§§ì€ ë…¸ë“œì˜ ê°œìˆ˜ë¥¼ ì…‰ë‹ˆë‹¤."""
    if len(node.get('text', '')) < threshold:
        count += 1
    for child in node.get('children', []):
        count = count_short_nodes(child, threshold, count)
    return count

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="ë²•ë¥  ë¬¸ì„œ ê³„ì¸µ ë¶„ì„ê¸°", page_icon="ğŸ›ï¸", layout="wide")

if 'analysis_result' not in st.session_state:
    st.session_state.analysis_result = None

# --- UI ë ˆì´ì•„ì›ƒ ---
st.title("ğŸ›ï¸ íƒœêµ­ ë²•ë¥  ë¬¸ì„œ ê³„ì¸µ ë¶„ì„ê¸° (v3.2)")
st.markdown(f"**LLM Model:** `{dp.MODEL_NAME}` (ìˆ˜ì •ì€ `document_processor.py`ì—ì„œ ê°€ëŠ¥)")
st.markdown("3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ê³¼ ìë™ ì¬ì‹œë„, ì„±ëŠ¥ ì¸¡ì •ì„ í†µí•´ ë²•ë¥  ë¬¸ì„œ êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

with st.expander("âš™ï¸ ê° ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •í•˜ê¸°"):
    tab1, tab2, tab3 = st.tabs(["1ë‹¨ê³„: Architect", "2ë‹¨ê³„: Surveyor", "3ë‹¨ê³„: Detailer"])

    with tab1:
        st.info("ë¬¸ì„œ ì „ì²´ì—ì„œ ìµœìƒìœ„ êµ¬ì¡°(Book, Part, Chapter)ë¥¼ ì°¾ëŠ” ì„ë¬´ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.")
        st.session_state.prompt1 = st.text_area(
            "Architect Prompt", value=dp.PROMPT_ARCHITECT, height=250
        )
    with tab2:
        st.info("ê° Chapter ë‚´ë¶€ì—ì„œ ì¤‘ê°„ êµ¬ì¡°(Section)ë¥¼ ì°¾ëŠ” ì„ë¬´ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.")
        st.session_state.prompt2 = st.text_area(
            "Surveyor Prompt", value=dp.PROMPT_SURVEYOR, height=250
        )
    with tab3:
        st.info("ê°€ì¥ ì‘ì€ ë‹¨ìœ„(Section ë˜ëŠ” Chapter) ë‚´ë¶€ì—ì„œ ìµœí•˜ìœ„ êµ¬ì¡°(Article)ë¥¼ ì°¾ëŠ” ì„ë¬´ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.")
        st.session_state.prompt3 = st.text_area(
            "Detailer Prompt", value=dp.PROMPT_DETAILER, height=250
        )

uploaded_file = st.file_uploader("ë¶„ì„í•  íƒœêµ­ ë²•ë¥  í…ìŠ¤íŠ¸ íŒŒì¼(.txt)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=['txt'])

if uploaded_file is not None:
    document_text = uploaded_file.getvalue().decode('utf-8')
    char_count = len(document_text)
    st.info(f"ğŸ“ ì—…ë¡œë“œëœ íŒŒì¼: **{uploaded_file.name}** | ì´ ê¸€ì ìˆ˜: **{char_count:,}** ì")

    if st.button("ê³„ì¸µ êµ¬ì¡° ë¶„ì„ ì‹¤í–‰", type="primary"):
        st.session_state.analysis_result = None
        
        @st.cache_data
        def get_debug_info_collector():
            return []
        
        debug_info_collector = get_debug_info_collector()
        debug_info_collector.clear()

        def display_intermediate_result(result, container, debug_info):
            llm_duration = next((item.get('llm_duration_seconds', 0) for item in debug_info if "step1_architect_response" in item), 0)
            container.write(f"âœ… 1ë‹¨ê³„ ì™„ë£Œ! (LLM ì‘ë‹µ ì‹œê°„: {llm_duration:.2f}ì´ˆ)")
            container.write("ì°¾ì•„ë‚¸ ìµœìƒìœ„ êµ¬ì¡°:")
            display_data = [{"type": n.get('type'), "title": n.get('title')} for n in result]
            container.dataframe(display_data)

        with st.status("3ë‹¨ê³„ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤...", expanded=True) as status:
            try:
                api_key = st.secrets["GEMINI_API_KEY"]
                final_result, debug_info = dp.run_pipeline(
                    document_text=document_text,
                    api_key=api_key,
                    status_container=status,
                    prompt_architect=st.session_state.prompt1,
                    prompt_surveyor=st.session_state.prompt2,
                    prompt_detailer=st.session_state.prompt3,
                    intermediate_callback=display_intermediate_result
                )
                
                st.session_state.analysis_result = {
                    "final": final_result,
                    "debug": debug_info,
                    "file_name": uploaded_file.name
                }
                status.update(label="âœ… ê³„ì¸µ ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)
                st.success("ğŸ‰ ì„±ê³µì ìœ¼ë¡œ ê³„ì¸µ íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤!")
                time.sleep(0.5)
                st.rerun()

            except Exception as e:
                st.session_state.analysis_result = None
                status.update(label="ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ", state="error", expanded=True)
                st.error(f"ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.code(traceback.format_exc())

if st.session_state.analysis_result:
    result = st.session_state.analysis_result
    final_result_data = result["final"]
    debug_info = result["debug"]
    file_name = result["file_name"]

    st.header("ğŸ“„ ë¶„ì„ ê²°ê³¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ")

    if "error" in final_result_data or not final_result_data.get("tree"):
        st.error("ë¶„ì„ ì‹¤íŒ¨: ë¬¸ì„œì—ì„œ ìœ íš¨í•œ êµ¬ì¡°ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë””ë²„ê·¸ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        short_node_threshold = 15
        total_short_nodes = sum(count_short_nodes(node, short_node_threshold) for node in final_result_data.get('tree', []))
        
        timings_list = [item for item in debug_info if "performance_timings" in item]
        if timings_list:
            timings = timings_list[0]['performance_timings']
            st.subheader("ğŸ“Š ë¶„ì„ ìš”ì•½")
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("1ë‹¨ê³„ (Architect)", f"{timings.get('step1_architect_duration', 0):.2f} ì´ˆ")
            col2.metric("2ë‹¨ê³„ (Surveyor)", f"{timings.get('step2_surveyor_duration', 0):.2f} ì´ˆ")
            col3.metric("3ë‹¨ê³„ (Detailer)", f"{timings.get('step3_detailer_duration', 0):.2f} ì´ˆ")
            col4.metric(f"ì§§ì€ ë…¸ë“œ (<{short_node_threshold}ì)", f"{total_short_nodes} ê°œ",
                        help=f"í…ìŠ¤íŠ¸ ë‚´ìš©ì´ {short_node_threshold}ì ë¯¸ë§Œì¸ ë…¸ë“œì˜ ìˆ˜ì…ë‹ˆë‹¤.",
                        delta=f"-{total_short_nodes}" if total_short_nodes > 0 else None,
                        delta_color="inverse" if total_short_nodes > 0 else "off")

    tab1, tab2 = st.tabs(["âœ”ï¸ ìµœì¢… ê²°ê³¼ (ê³„ì¸µ íŠ¸ë¦¬)", "ğŸ ìƒì„¸ ë””ë²„ê·¸ ë¡œê·¸"])

    with tab1:
        st.json(final_result_data, expanded=True)
        st.download_button(
           label="ê²°ê³¼ íŠ¸ë¦¬ (JSON) ë‹¤ìš´ë¡œë“œ",
           data=json.dumps(final_result_data, indent=2, ensure_ascii=False),
           file_name=f"{file_name.split('.')[0]}_pipeline_tree.json",
           mime="application/json",
        )

    with tab2:
        st.write("íŒŒì´í”„ë¼ì¸ ê° ë‹¨ê³„ì—ì„œ LLMì´ ë°˜í™˜í•œ ì›ë³¸ ë°ì´í„° ë“± ìƒì„¸í•œ ë¡œê·¸ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.")
        st.json({"pipeline_logs": debug_info}, expanded=False)
        st.download_button(
           label="ë””ë²„ê·¸ ë¡œê·¸ (JSON) ë‹¤ìš´ë¡œë“œ",
           data=json.dumps(debug_info, indent=2, ensure_ascii=False),
           file_name=f"{file_name.split('.')[0]}_pipeline_debug.json",
           mime="application/json",
        )